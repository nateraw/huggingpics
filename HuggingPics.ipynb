{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HuggingPics.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nateraw/huggingpics/blob/main/HuggingPics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ApFglcc3TASu"
      },
      "source": [
        "# HuggingPics ü§óüñºÔ∏è\n",
        "\n",
        "Fine-tune Vision Transformers for **anything** using images found on the web."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XVyU3ScYZ3Hc"
      },
      "source": [
        "! pip install transformers pytorch-lightning --quiet\n",
        "! sudo apt -qq install git-lfs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ihFempth1zK0"
      },
      "source": [
        "import requests\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "import shutil\n",
        "from getpass import getpass\n",
        "from PIL import Image\n",
        "from requests.exceptions import HTTPError\n",
        "from io import BytesIO\n",
        "from pathlib import Path\n",
        "import torch\n",
        "import pytorch_lightning as pl\n",
        "from huggingface_hub import HfApi, Repository\n",
        "from torch.utils.data import DataLoader\n",
        "from torchmetrics import Accuracy\n",
        "from torchvision.datasets import ImageFolder\n",
        "from transformers import ViTFeatureExtractor, ViTForImageClassification"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Utxw4wj-RS94"
      },
      "source": [
        "## Defining your search terms\n",
        "\n",
        "Simply replace the terms in the widget below with whatever you want to classify, and we'll download ~150 images for each class for you.\n",
        "\n",
        "You can define up to 5 classes. For < 5 classes, just leave the remaining text boxes blank.\n",
        "\n",
        "### Examples\n",
        "\n",
        "üí° If you need some inspiration, take a look at these examples:\n",
        "\n",
        "|            | [nateraw/rare-puppers](https://huggingface.co/nateraw/rare-puppers) | [nateraw/pasta-pizza-ravioli](https://huggingface.co/nateraw/pasta-pizza-ravioli) | [nateraw/baseball-stadium-foods](https://huggingface.co/nateraw/baseball-stadium-foods) | [nateraw/denver-nyc-paris](https://huggingface.co/nateraw/denver-nyc-paris) |\n",
        "| ---------- | ------------------------------------------------------------------- | --------------------------------------------------------------------------------- | --------------------------------------------------------------------------------------- | --------------------------------------------------------------------------- |\n",
        "| **term_1** | samoyed                                                             | pizza                                                                             | cotton candy                                                                            | denver                                                                      |\n",
        "| **term_2** | shiba inu                                                           | pasta                                                                             | hamburger                                                                               | new york city                                                               |\n",
        "| **term_3** | corgi                                                               | ravioli                                                                           | hot dog                                                                                 | paris                                                                       |\n",
        "| **term_4** |                                                                     |                                                                                   | nachos                                                                                  |                                                                             |\n",
        "| **term_5** |                                                                     |                                                                                   | popcorn                                                                                 |                                                                             |\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JGyijnL08Cge",
        "cellView": "form"
      },
      "source": [
        "term_1 = \"samoyed\" #@param {type:\"string\"}\n",
        "term_2 = \"shiba inu\" #@param {type:\"string\"}\n",
        "term_3 = \"corgi\" #@param {type:\"string\"}\n",
        "term_4 = \"\" #@param {type:\"string\"}\n",
        "term_5 = \"\" #@param {type:\"string\"}\n",
        "\n",
        "search_terms = sorted([\n",
        "    term_1,\n",
        "    term_2,\n",
        "    term_3,\n",
        "    term_4,\n",
        "    term_5\n",
        "])\n",
        "\n",
        "search_terms = [x for x in search_terms if x.strip() != '']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8O-Z8-k3DByn"
      },
      "source": [
        "## Get Images From The Web\n",
        "\n",
        "Here, we loop over your selected search terms and collect ~150 related images for each.\n",
        "\n",
        "We'll save them to a new folder named `images/` that is structured to work with [`torchvision.datasets.ImageFolder`](https://pytorch.org/vision/stable/datasets.html#torchvision.datasets.ImageFolder)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jJEH5b3rsdId"
      },
      "source": [
        "SEARCH_URL = \"https://huggingface.co/api/experimental/images/search\"\n",
        "\n",
        "def get_image_urls_by_term(search_term: str, count=150):\n",
        "    params  = {\"q\": search_term, \"license\": \"public\", \"imageType\": \"photo\", \"count\": count}\n",
        "    response = requests.get(SEARCH_URL, params=params)\n",
        "    response.raise_for_status()\n",
        "    response_data = response.json()\n",
        "    image_urls = [img['thumbnailUrl'] for img in response_data['value']]\n",
        "    return image_urls\n",
        "\n",
        "\n",
        "def gen_images_from_urls(urls):\n",
        "    num_skipped = 0\n",
        "    for url in urls:\n",
        "        response = requests.get(url)\n",
        "        if not response.status_code == 200:\n",
        "            num_skipped += 1\n",
        "            yield None\n",
        "        img = Image.open(BytesIO(response.content))\n",
        "        yield img\n",
        "    print(f\"Retrieved {len(urls) - num_skipped} images. Skipped {num_skipped}.\")\n",
        "\n",
        "\n",
        "def urls_to_image_folder(urls, save_directory):\n",
        "    for i, image in enumerate(gen_images_from_urls(urls)):\n",
        "        image.save(save_directory / f'{i}.jpg')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PKBb34N9qnNS"
      },
      "source": [
        "data_dir = Path('images')\n",
        "\n",
        "if data_dir.exists():\n",
        "    shutil.rmtree(data_dir)\n",
        "\n",
        "for search_term in search_terms:\n",
        "    search_term_dir = data_dir / search_term\n",
        "    search_term_dir.mkdir(exist_ok=True, parents=True)\n",
        "    urls = get_image_urls_by_term(search_term)\n",
        "    print(f\"Saving images of {search_term} to {str(search_term_dir)}...\")\n",
        "    urls_to_image_folder(urls, search_term_dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v_r5KO0aMIsn"
      },
      "source": [
        "## Init Dataset and Split into Training and Validation Sets\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U4vCcep26Em6"
      },
      "source": [
        "ds = ImageFolder(data_dir)\n",
        "indices = torch.randperm(len(ds)).tolist()\n",
        "n_val = math.floor(len(indices) * .15)\n",
        "train_ds = torch.utils.data.Subset(ds, indices[:-n_val])\n",
        "val_ds = torch.utils.data.Subset(ds, indices[-n_val:])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ABreTsYRoDzy"
      },
      "source": [
        "## Show Some Examples\n",
        "\n",
        "#### ‚ö†Ô∏è Note - The image search API isn't perfect ‚ö†Ô∏è\n",
        "\n",
        "You may need to go back, tweak your search terms, and repeat the cells above until the images shown below look good.\n",
        "\n",
        "A few bad images is OK, but if they are completely incorrect, you'll definitely want to try again with different terms."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wbzsRQRe6iY5"
      },
      "source": [
        "plt.figure(figsize=(20,10))\n",
        "num_examples_per_class = 5\n",
        "i = 1\n",
        "for class_idx, class_name in enumerate(ds.classes):\n",
        "    folder = ds.root / class_name\n",
        "    for image_idx, image_path in enumerate(sorted(folder.glob('*'))):\n",
        "        if image_path.suffix in ds.extensions:\n",
        "            image = Image.open(image_path)\n",
        "            plt.subplot(len(ds.classes), num_examples_per_class, i)\n",
        "            ax = plt.gca()\n",
        "            ax.set_title(\n",
        "                class_name,\n",
        "                size='xx-large',\n",
        "                pad=5,\n",
        "                loc='left',\n",
        "                y=0,\n",
        "                backgroundcolor='white'\n",
        "            )\n",
        "            ax.axis('off')\n",
        "            plt.imshow(image)\n",
        "            i += 1\n",
        "\n",
        "            if image_idx + 1 == num_examples_per_class:\n",
        "                break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "96LqcgYfLGc8"
      },
      "source": [
        "## Preparing Labels for Our Model's Config\n",
        "\n",
        "By adding `label2id` + `id2label` to our model's config, we'll get friendlier labels in the inference API."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mh0yxRKDGDd5"
      },
      "source": [
        "label2id = {}\n",
        "id2label = {}\n",
        "\n",
        "for i, class_name in enumerate(ds.classes):\n",
        "    label2id[class_name] = str(i)\n",
        "    id2label[str(i)] = class_name"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-1aly6Vrx2mM"
      },
      "source": [
        "## Image Classification Collator\n",
        "\n",
        "To apply our transforms to images, we'll use a custom collator class. We'll initialize it using an instance of `ViTFeatureExtractor` and pass the collator instance to `torch.utils.data.DataLoader`'s `collate_fn` kwarg."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D2n0Mf1u1ymf"
      },
      "source": [
        "class ImageClassificationCollator:\n",
        "    def __init__(self, feature_extractor):\n",
        "        self.feature_extractor = feature_extractor\n",
        " \n",
        "    def __call__(self, batch):\n",
        "        encodings = self.feature_extractor([x[0] for x in batch], return_tensors='pt')\n",
        "        encodings['labels'] = torch.tensor([x[1] for x in batch], dtype=torch.long)\n",
        "        return encodings "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T62uFtK7LTcz"
      },
      "source": [
        "## Init Feature Extractor, Model, Data Loaders\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YovQELKD4Bu8"
      },
      "source": [
        "feature_extractor = ViTFeatureExtractor.from_pretrained('google/vit-base-patch16-224-in21k')\n",
        "model = ViTForImageClassification.from_pretrained(\n",
        "    'google/vit-base-patch16-224-in21k',\n",
        "    num_labels=len(label2id),\n",
        "    label2id=label2id,\n",
        "    id2label=id2label\n",
        ")\n",
        "collator = ImageClassificationCollator(feature_extractor)\n",
        "train_loader = DataLoader(train_ds, batch_size=8, collate_fn=collator, num_workers=2, shuffle=True)\n",
        "val_loader = DataLoader(val_ds, batch_size=8, collate_fn=collator, num_workers=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lEgf32rC7pQh"
      },
      "source": [
        "# Training\n",
        "\n",
        "‚ö° We'll use [PyTorch Lightning](https://pytorchlightning.ai/) to fine-tune our model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UIIRpEzW4LFo"
      },
      "source": [
        "class Classifier(pl.LightningModule):\n",
        "\n",
        "    def __init__(self, model, lr: float = 2e-5, **kwargs):\n",
        "        super().__init__()\n",
        "        self.save_hyperparameters('lr', *list(kwargs))\n",
        "        self.model = model\n",
        "        self.forward = self.model.forward\n",
        "        self.val_acc = Accuracy()\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        outputs = self(**batch)\n",
        "        self.log(f\"train_loss\", outputs.loss)\n",
        "        return outputs.loss\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        outputs = self(**batch)\n",
        "        self.log(f\"val_loss\", outputs.loss)\n",
        "        acc = self.val_acc(outputs.logits.argmax(1), batch['labels'])\n",
        "        self.log(f\"val_acc\", acc, prog_bar=True)\n",
        "        return outputs.loss\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        return torch.optim.Adam(self.parameters(), lr=self.hparams.lr)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wTWYA1rf3Heg"
      },
      "source": [
        "pl.seed_everything(42)\n",
        "classifier = Classifier(model, lr=2e-5)\n",
        "trainer = pl.Trainer(gpus=1, precision=16, max_epochs=4)\n",
        "trainer.fit(classifier, train_loader, val_loader)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eJLxkmefLZT0"
      },
      "source": [
        "## Check if it Worked üòÖ"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tDfUUwH73LSq"
      },
      "source": [
        "val_batch = next(iter(val_loader))\n",
        "outputs = model(**val_batch)\n",
        "print('Preds: ', outputs.logits.softmax(1).argmax(1))\n",
        "print('Labels:', val_batch['labels'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4FlEoisI9S-e"
      },
      "source": [
        "# Push to ü§ó Hub üöÄ\n",
        "\n",
        "You'll need your HuggingFace username and password to authenticate, so make sure to [sign up](https://huggingface.co/join) if you haven't already.\n",
        "\n",
        "Your repo will be created at `{hf_username}/{model_id}`, so pick a `model_id` you like üòä"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t58j9AN-iELM",
        "cellView": "form"
      },
      "source": [
        "model_id = \"rare-puppers\" #@param {type:\"string\"}\n",
        "hf_username = \"nateraw\" #@param {type:\"string\"}\n",
        "\n",
        "description = \"\"\"\n",
        "Autogenerated by HuggingPicsü§óüñºÔ∏è\n",
        "\n",
        "Create your own image classifier for **anything** by running [the demo](https://colab.research.google.com/github/nateraw/huggingpics/blob/main/HuggingPics.ipynb).\n",
        "\n",
        "Report any issues with the demo at the [github repo](https://github.com/nateraw/huggingpics).\n",
        "\"\"\"\n",
        "task_name = \"Image Classification\"\n",
        "task_type = 'image-classification'\n",
        "metric_name = 'Accuracy'\n",
        "metric_type = 'accuracy'\n",
        "metric_value = trainer.callback_metrics['val_acc'].item()\n",
        "hf_password = getpass(\"Enter your HuggingFace password\")\n",
        "\n",
        "# Delete model folder, as we (re)create it here.\n",
        "if Path('./model').exists():\n",
        "    shutil.rmtree('./model')\n",
        "\n",
        "token = HfApi().login(username=hf_username, password=hf_password)\n",
        "del hf_password\n",
        "model_url = HfApi().create_repo(token=token, name=model_id, exist_ok=True)\n",
        "model_repo = Repository(\"./model\", clone_from=model_url, use_auth_token=token, git_email=f"{hf_username}@users.noreply.huggingface.co", git_user=hf_username)\n",
        "model.save_pretrained(model_repo.local_dir)\n",
        "feature_extractor.save_pretrained(model_repo.local_dir)\n",
        "\n",
        "# Copy over tensorboard logs from lightning_logs/ into ./model/runs/\n",
        "tensorboard_logs_path = next(Path(trainer.logger.log_dir).glob('events.out*'))\n",
        "model_repo_logs_path = Path(model_repo.local_dir) / 'runs'\n",
        "model_repo_logs_path.mkdir(exist_ok=True, parents=True)\n",
        "shutil.copy(tensorboard_logs_path, model_repo_logs_path)\n",
        "\n",
        "# Copy over a few example images\n",
        "example_images_dir = Path(model_repo.local_dir) / 'images'\n",
        "example_images_dir.mkdir(exist_ok=True, parents=True)\n",
        "image_markdown_template = '''\n",
        "#### {class_name}\n",
        "\n",
        "![{class_name}](images/{example_image_path})\n",
        "'''\n",
        "example_images_markdown = \"\"\n",
        "for class_idx, class_name in enumerate(ds.classes):\n",
        "    folder = ds.root / class_name\n",
        "    image_path = sorted(folder.glob('*'))[0]\n",
        "    example_image_path = example_images_dir / f\"{class_name.replace(' ', '_')}{image_path.suffix}\"\n",
        "    shutil.copy(image_path, example_image_path)\n",
        "    example_images_markdown += image_markdown_template.format(\n",
        "        class_name=class_name,\n",
        "        example_image_path=example_image_path.name\n",
        "    )\n",
        "\n",
        "\n",
        "# Prepare README.md from information gathered above\n",
        "readme_txt = f\"\"\"\n",
        "---\n",
        "tags:\n",
        "- image-classification\n",
        "- pytorch\n",
        "- huggingpics\n",
        "metrics:\n",
        "- {metric_type}\n",
        "\n",
        "model-index:\n",
        "- name: {model_id}\n",
        "  results:\n",
        "  - task:\n",
        "      name: {task_name}\n",
        "      type: {task_type}\n",
        "    metrics:\n",
        "      - name: {metric_name}\n",
        "        type: {metric_type}\n",
        "        value: {metric_value}\n",
        "---\n",
        "\n",
        "# {model_id}\n",
        "\n",
        "{description}\n",
        "\n",
        "## Example Images\n",
        "\n",
        "{example_images_markdown}\n",
        "\n",
        "\"\"\".strip()\n",
        "\n",
        "(Path(model_repo.local_dir) / 'README.md').write_text(readme_txt)\n",
        "\n",
        "commit_url = model_repo.push_to_hub()\n",
        "\n",
        "print(\"Check out your model at:\")\n",
        "print(f\"https://huggingface.co/{hf_username}/{model_id}\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}